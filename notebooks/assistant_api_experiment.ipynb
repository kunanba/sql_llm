{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from langfuse.decorators import observe\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_API_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv('AZURE_OPENAI_VERSION')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "# Function to retrieve the schema from ROAPI\n",
    "def get_roapi_schema():\n",
    "    url = \"http://roapi-app-arash.dhbjd9bvccbjedea.eastus.azurecontainer.io:8000/api/schema\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Error retrieving schema:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function to get the current date\n",
    "def get_current_date():\n",
    "    return datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Function to create an assistant\n",
    "@observe()\n",
    "def create_assistant(formatted_date):\n",
    "    \n",
    "    assistant_instructions = f\"\"\"\n",
    "Given a user question related to the data in the database, first generate the SQL query that conforms to PostgreSQL SQL dialect. Pay attention to the columns that need to be in double quotes and the ones that should not be. \n",
    "Please pay close attention to the following points:\n",
    "1- 'channel' is an alias to 'device_class', so if the user asks for count of 'channel' you need to do the count of 'device_class'.\n",
    "2- 'is_live' indicates whether the video is live or not, so use this if you want to calculate on-demand versus live.\n",
    "3- If you need to compare numbers such as 'duration' or anything else, and the results are all zero, you should not rank them.\n",
    "4- The format of the date is like '2024-07-03', so you might need to do some formatting to get the date in the right format.\n",
    "5- If you are asked for analysis over days, months, or time, you might need to look up 'days', 'months', and 'time' columns, and that is not part of 'date' column.\n",
    "6- For video duration use 'duration' column, not 'video_duration' column.\n",
    "\n",
    "Below are some examples of the SQL queries:\n",
    "1- SELECT COUNT(DISTINCT user_id) AS active_user_count FROM bitmovin WHERE date >= to_date(cast(now() AS VARCHAR)) - INTERVAL '200 days' AND user_id IS NOT NULL;\n",
    "2- SELECT * FROM bitmovin WHERE date >= to_date('{formatted_date}') - INTERVAL '200 days' AND user_id IS NOT NULL LIMIT 10;\n",
    "3- SELECT \"AccountType\", \"DeviceType\", \"ApiName\", COUNT(*) AS api_usage_count FROM asl GROUP BY \"AccountType\", \"DeviceType\", \"ApiName\" ORDER BY \"AccountType\", \"DeviceType\", api_usage_count DESC;\n",
    "4- SELECT asl.\"TenantId\", asl.\"DeviceType\", bitmovin.\"browser\", COUNT(*) AS usage_count, AVG(bitmovin.\"page_load_time\") AS avg_page_load_time, AVG(bitmovin.\"startuptime\") AS avg_startup_time FROM asl JOIN bitmovin ON asl.\"TenantId\" = bitmovin.\"tenant\" GROUP BY asl.\"TenantId\", asl.\"DeviceType\", bitmovin.\"browser\" ORDER BY usage_count DESC LIMIT 10;\n",
    "\n",
    "Make sure to make date queries align to today's date {formatted_date}.\n",
    "\n",
    "Then tell me the SQL query that you will use.\n",
    "\"\"\"\n",
    "\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"SQL Assistant\",\n",
    "        description=\"An assistant that generates SQL queries for ROAPI.\",\n",
    "        model=\"gpt-4\",  # Replace with your deployed Azure OpenAI model\n",
    "        tools=[],  # No tools are necessary for SQL generation\n",
    "        instructions=assistant_instructions\n",
    "    )\n",
    "    return assistant\n",
    "\n",
    "\n",
    "# Function to create a thread\n",
    "@observe()\n",
    "def create_thread(user_input, schema):\n",
    "    # Prepare the initial message with the schema\n",
    "    initial_message = f\"\"\"\n",
    "Database schema:\n",
    "{json.dumps(schema, indent=2)}\n",
    "\n",
    "User request:\n",
    "{user_input}\n",
    "\"\"\"\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": initial_message}\n",
    "        ]\n",
    "    )\n",
    "    return thread\n",
    "\n",
    "# Function to run the assistant and process user input\n",
    "@observe()\n",
    "def run_thread(thread_id, assistant_id):\n",
    "    # Start a new run\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id\n",
    "    )\n",
    "\n",
    "    # Poll for results\n",
    "    while run.status not in [\"completed\", \"failed\", \"cancelled\"]:\n",
    "        time.sleep(1)  # Wait for 1 second before checking the status again\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread_id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "\n",
    "    if run.status == \"completed\":\n",
    "        # Retrieve the generated SQL query\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "        assistant_messages = [m for m in messages.data if m.role == \"assistant\"]\n",
    "        if assistant_messages:\n",
    "            assistant_message = assistant_messages[-1]\n",
    "            return assistant_message.content\n",
    "        else:\n",
    "            print(\"Error: No response from assistant.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Run failed with status: {run.status}\")\n",
    "        return None\n",
    "    \n",
    "# Function to execute SQL query against ROAPI\n",
    "@observe()\n",
    "def execute_sql_query(sql_query):\n",
    "    url = \"http://roapi-app-arash.dhbjd9bvccbjedea.eastus.azurecontainer.io:8000/api/sql\"\n",
    "\n",
    "    print(\"SQL Query: \", sql_query)\n",
    "    response = requests.post(url, data=sql_query, headers={\"Content-Type\": \"application/json\"})\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            return response.json()\n",
    "        except json.JSONDecodeError:\n",
    "            return response.text\n",
    "    else:\n",
    "        print(\"Error executing SQL query:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Step 1: Get the schema\n",
    "    schema = get_roapi_schema()\n",
    "    if schema is None:\n",
    "        return\n",
    "\n",
    "    # Step 2: Create an assistant\n",
    "    assistant = create_assistant()\n",
    "    print(\"Assistant created:\", assistant.id)\n",
    "\n",
    "    # Step 3: User input\n",
    "    user_input = input(\"Enter your query request: \")\n",
    "\n",
    "    # Step 4: Create a thread\n",
    "    thread = create_thread(user_input=user_input, schema=schema)\n",
    "    print(\"Thread created:\", thread.id)\n",
    "\n",
    "    # Step 5: Run the assistant\n",
    "    sql_query = run_thread(thread_id=thread.id, assistant_id=assistant.id)\n",
    "    if sql_query:\n",
    "        print(\"\\nGenerated SQL Query:\")\n",
    "        print(sql_query)\n",
    "\n",
    "        # Step 6: Execute the SQL query\n",
    "        result = execute_sql_query(sql_query)\n",
    "        if result:\n",
    "            print(\"\\nQuery Result:\")\n",
    "            print(json.dumps(result, indent=2))\n",
    "        else:\n",
    "            print(\"No results returned.\")\n",
    "    else:\n",
    "        print(\"Failed to generate a SQL query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_assistant() missing 1 required positional argument: 'formatted_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 127\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Step 2: Create an assistant\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m assistant \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_assistant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssistant created:\u001b[39m\u001b[38;5;124m\"\u001b[39m, assistant\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Step 3: User input\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\armoshar\\AppData\\Local\\anaconda3\\envs\\gen-ai\\Lib\\site-packages\\langfuse\\decorators\\langfuse_decorator.py:254\u001b[0m, in \u001b[0;36mLangfuseDecorator._sync_observe.<locals>.sync_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize_call(\n\u001b[0;32m    257\u001b[0m         observation, result, capture_output, transform_to_string\n\u001b[0;32m    258\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\armoshar\\AppData\\Local\\anaconda3\\envs\\gen-ai\\Lib\\site-packages\\langfuse\\decorators\\langfuse_decorator.py:513\u001b[0m, in \u001b[0;36mLangfuseDecorator._handle_exception\u001b[1;34m(self, observation, e)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation:\n\u001b[0;32m    510\u001b[0m     _observation_params_context\u001b[38;5;241m.\u001b[39mget()[observation\u001b[38;5;241m.\u001b[39mid]\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    511\u001b[0m         level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m, status_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)\n\u001b[0;32m    512\u001b[0m     )\n\u001b[1;32m--> 513\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\armoshar\\AppData\\Local\\anaconda3\\envs\\gen-ai\\Lib\\site-packages\\langfuse\\decorators\\langfuse_decorator.py:252\u001b[0m, in \u001b[0;36mLangfuseDecorator._sync_observe.<locals>.sync_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    249\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 252\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(observation, e)\n",
      "\u001b[1;31mTypeError\u001b[0m: create_assistant() missing 1 required positional argument: 'formatted_date'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to retrieve the schema from ROAPI\n",
    "def get_roapi_schema():\n",
    "    url = \"http://roapi-app-arash.dhbjd9bvccbjedea.eastus.azurecontainer.io:8000/api/schema\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        schema = response.json()\n",
    "        return schema\n",
    "    else:\n",
    "        print(\"Error retrieving schema:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Function to wait for run completion\n",
    "def wait_for_run_completion(thread_id, run_id):\n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n",
    "        if run.status in ['completed', 'failed', 'incomplete']:\n",
    "            return run\n",
    "        else:\n",
    "            time.sleep(1)  # Wait before checking again\n",
    "\n",
    "# Main function to interact with the user\n",
    "def main():\n",
    "    # Step 1: Get the schema\n",
    "    schema = get_roapi_schema()\n",
    "    if schema is None:\n",
    "        return\n",
    "\n",
    "    # Save the schema to a file\n",
    "    with open(\"schema.json\", \"w\") as f:\n",
    "        json.dump(schema, f)\n",
    "\n",
    "    # Upload the schema file to the Assistant\n",
    "    schema_file = client.files.create(\n",
    "        file=open(\"schema.json\", \"rb\"),\n",
    "        purpose='assistants'\n",
    "    )\n",
    "\n",
    "    # Step 2: Create the Assistant\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"SQL Query Generator\",\n",
    "        instructions=\"\"\"\n",
    "You are an assistant that generates SQL queries in PostgreSQL dialect based on user requests.\n",
    "Use the database schema provided to generate syntactically correct SQL queries that consider the schema.\n",
    "\n",
    "When providing the SQL query, please enclose it within <SQL></SQL> tags to make it easier to extract.\n",
    "\"\"\",\n",
    "        model=\"gpt-4\",\n",
    "        tools=[{\"type\": \"file_search\"}],\n",
    "        tool_resources={\n",
    "            \"file_search\": {\n",
    "                \"file_ids\": [schema_file.id]\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Step 3: Get user input\n",
    "    user_input = input(\"Please enter your request: \")\n",
    "\n",
    "    # Create a Thread with the user's message\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_input\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Step 4: Run the Assistant on the Thread\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id\n",
    "    )\n",
    "\n",
    "    # Wait for the run to complete\n",
    "    run = wait_for_run_completion(thread.id, run.id)\n",
    "    if run.status != 'completed':\n",
    "        print(\"Run did not complete successfully. Status:\", run.status)\n",
    "        return\n",
    "\n",
    "    # Step 5: Retrieve the Assistant's response\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    assistant_message = None\n",
    "    for message in messages.data[::-1]:\n",
    "        if message.role == 'assistant':\n",
    "            assistant_message = message\n",
    "            break\n",
    "\n",
    "    if assistant_message is None:\n",
    "        print(\"No assistant response found.\")\n",
    "        return\n",
    "\n",
    "    # Extract the content from the assistant's message\n",
    "    assistant_content = ''.join([item['text']['value'] for item in assistant_message.content if item['type'] == 'text'])\n",
    "\n",
    "    print(\"\\nAssistant's Response:\")\n",
    "    print(assistant_content)\n",
    "\n",
    "    # Step 6: Extract SQL query from the assistant's response\n",
    "    import re\n",
    "    match = re.search(r'<SQL>(.*?)</SQL>', assistant_content, re.DOTALL)\n",
    "    if match:\n",
    "        sql_query = match.group(1).strip()\n",
    "        print(\"\\nGenerated SQL Query:\")\n",
    "        print(sql_query)\n",
    "    else:\n",
    "        print(\"No SQL query found in the assistant's response.\")\n",
    "        return\n",
    "\n",
    "    # Step 7: Execute the SQL query against ROAPI\n",
    "    url = \"http://roapi-app-arash.dhbjd9bvccbjedea.eastus.azurecontainer.io:8000/api/sql\"\n",
    "    response = requests.post(url, data=sql_query, headers={\"Content-Type\": \"application/json\"})\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            result = response.json()\n",
    "            print(\"\\nQuery Result:\")\n",
    "            print(json.dumps(result, indent=2))\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error decoding JSON response.\")\n",
    "            print(response.text)\n",
    "    else:\n",
    "        print(\"Error executing SQL query:\", response.status_code)\n",
    "        print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Unknown parameter: 'tool_resources.file_search.file_ids'.\", 'type': 'invalid_request_error', 'param': 'tool_resources.file_search.file_ids', 'code': 'unknown_parameter'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 39\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m     schema_file \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     34\u001b[0m         file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     35\u001b[0m         purpose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124massistants\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     36\u001b[0m     )\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Step 2: Create the Assistant\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     assistant \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massistants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSQL Query Generator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstructions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;43mYou are an assistant that generates SQL queries in PostgreSQL dialect based on user requests.\u001b[39;49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;43mUse the database schema provided to generate syntactically correct SQL queries that consider the schema.\u001b[39;49m\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;43mWhen providing the SQL query, please enclose it within <SQL></SQL> tags to make it easier to extract.\u001b[39;49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile_search\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile_search\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mschema_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Step 3: Get user input\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease enter your request: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\armoshar\\AppData\\Local\\anaconda3\\envs\\gen-ai\\Lib\\site-packages\\openai\\resources\\beta\\assistants.py:146\u001b[0m, in \u001b[0;36mAssistants.create\u001b[1;34m(self, model, description, instructions, metadata, name, response_format, temperature, tool_resources, tools, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03mCreate an assistant with a model and instructions.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/assistants\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_resources\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43massistant_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAssistantCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAssistant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\armoshar\\AppData\\Local\\anaconda3\\envs\\gen-ai\\Lib\\site-packages\\openai\\_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1277\u001b[0m     )\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\armoshar\\AppData\\Local\\anaconda3\\envs\\gen-ai\\Lib\\site-packages\\openai\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\armoshar\\AppData\\Local\\anaconda3\\envs\\gen-ai\\Lib\\site-packages\\openai\\_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1068\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Unknown parameter: 'tool_resources.file_search.file_ids'.\", 'type': 'invalid_request_error', 'param': 'tool_resources.file_search.file_ids', 'code': 'unknown_parameter'}}"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
